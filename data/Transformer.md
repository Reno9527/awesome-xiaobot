|名称|作者|读者数量|内容数量|创建时间|更新时间|
---
|[Transformer 最后一公里](https://xiaobot.net/p/Transformer?refer=0b133df9-27dc-423b-8101-639049001c13)|@董董灿|138人|64篇|2024-04-18|2024-08-03|

# 最近更新
## Qwen2 的模型结构和细节Qwen2（千问）是由阿里云开发的人工智能大模型，可用于智能对话，是一个典型的 Decoder-Only 结构。

该模型在很多任务上有着非常不错的表现，很多公司都会基于......
## GPT 和 BERT 的模型结构上一节介绍了什么是 Decoder-Only 结构，并且提到，目前绝大多数的大模型采用的都是 Decoder-Only 结构。虽然如此，仍然一些模型会用到 Encoder 部分作为主要架构，典型......
## 什么是 Decoder-Only 结构在《Attention is all you need》这篇论文中，作者给出了 Transformer 架构的完整图示。
一般来说，上图中左侧的部分被称为编码器，右侧的部分被称为解码......
## 后处理：预测得分的温度参数和 Softmax 计算如果你调用过大模型的 API，或者创作过智能体的话，大概率你调整过一些用来控制模型生成效果的参数。

下图展示的是我在微调某个智能体时后台的参数设置界面，里面有一个多样性......
## 后处理：预测得分的 Top_p 采样在上一节介绍了 Top_k 采样之后，接下来再看另一个非常常用的采样方法，叫做 Top_p 采样。

Top_p  采样中的 “p” 是 “probability”（概率......
## 后处理：预测得分的 Top_k 采样在对大模型的输出 Logits 的后处理过程中，除了上一节提到的对分数进行重复惩罚之外，采样也是一个非常重要的步骤。

合理的采样算法和采样阈值的设置，可以使模型生成的内......
## 后处理：为什么要对预测得分进行惩罚？从本节开始，会对大模型的后处理部分用到的一些经典的算法原理进行介绍。

所谓后处理，是指在大模型生成文本后，对生成的结果进行一系列的调整和优化，以确保输出的文本具有更好的......
## 如何实现 KVCache？在上一节了解了 KVCache 提出的背景之后，本节来看一下如何实现 KVCache。

Q/K/V 都可以用矩阵来表示。在一个二维矩阵中，表示 K 和 V 的方式是一样......
## 大模型的推理过程：KVCache 的引入(Prefill 和 Decode)在前面介绍完位置编码后，我们来从模型的视角看一个大模型中非常重要的技术，那就是 KVCache 缓存技术。

乍一看这个技术好像很深奥，又是 KV 又是缓存的，但是，如果......
## 位置编码：一文彻底搞懂旋转位置编码上一节介绍了基于三角函数的位置编码，本节介绍旋转位置编码。

个人感觉旋转位置编码背后的思想非常的精妙，它的主要目的是利用一系列的算法，可以表达出句子内词与词之间的相对位......

